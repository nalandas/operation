#!/bin/bash
#set -x 
source ./utils

usage() {
  echo "Options:"
  echo " -h, --help                              Show help info"
  echo " -a, --namenode <namenode host>          Hadoop HDFS namdenode host, default: localhost."
  echo " -p, --fs-port <namenode FS port>        Hadoop HDFS namdenode FS port, default: 8020."
  echo " -n, --node <node number>                Hadoop HDFS datanode number, default: 3"
  echo " -o, --host-if <ethernet interface>      Ethernet interface which is used to communicate with the datanode on host, default: 'eth0'"
  echo " -c, --container-if <ethernet interface> Ethernet interface which is used to assign IP address on container, default: 'eth1'"
  echo " -m, --image <docker image>              Docker image name, default: hadoop-cdh5-hdfs-datanode:0.0.1"
  echo " -i, --container-ip <docker ip>          IP address of contatiner, example: dhcp or 192.168.200.23/24@192.168.200.1, if it does not provided, will use the ip address on hosts for port mapping."
}

function get_opts() {
  OPTS=`getopt -o vha:p:n:o:c:m:i: -l help -l node: -l namenode: -l fs-port: -l host-if: -l container-if: -l image: -l container-ip: -- "$@"`
  if [ $? != 0 ]
  then
    usage
    exit 1
  fi
  eval set -- "$OPTS"
  # Default values
  HDFS_NN_SERVER=localhost
  HDFS_NN_PORT=8020
  CONTAINER_IP=""
  NODE_COUNT=3
  HOST_INTERFACE=eth0
  CONTAINER_IF=eth1
  IMAGE_NAME=hadoop-cdh5-hdfs-datanode:0.0.1
  while true ; do
    case "$1" in
        -h|--help) usage; exit 1;;
        -a|--namenode) HDFS_NN_SERVER=$2; shift 2;;
        -p|--fs-port) HDFS_NN_PORT=$2; shift 2;;
        -n|--node) NODE_COUNT=$2; shift 2;;
        -o|--host-if) HOST_INTERFACE=$2; shift 2;;
        -c|--container-if) CONTAINER_IF=$2; shift 2;;
        -m|--image) IMAGE_NAME=$2; shift 2;;
        -i|--container-ip) CONTAINER_IP=$2; shift 2;;
        --) shift; break;;
    esac
  done
}

current_dir=$(pwd)
get_opts $@

script_prefix="hdfs_datanode"

local_ip="$(ifconfig $HOST_INTERFACE | grep 'inet ' | awk '{print $2}')"
if [[ $local_ip == addr:* ]]; then
  local_ip=${local_ip#*addr:}
fi
for (( i=1; i<=$NODE_COUNT; i++ ))
do
  port1=$(expr 50010 + $i - 1)
  port2=$(expr 50020 + $i - 1)
  port3=$(expr 50075 + $i - 1)
  port4=$(expr 50475 + $i - 1)
  SDN_IP=$(get_new_sdn_ip "$CONTAINER_IP" $i)
  script_file=${script_prefix}_${i}_temp.sh
  container_name=${script_prefix}_$i
  echo "SDN_IP: $SDN_IP"
  sudo docker rm -f $container_name
  echo "CONTAINER_IF=$CONTAINER_IF
i=$i
local_ip=$local_ip
IMAGE_NAME=$IMAGE_NAME
HOST_INTERFACE=$HOST_INTERFACE
SDN_IP=$SDN_IP
HDFS_DATANODE_SERVER_PORT=$port1
HDFS_DATANODE_IPC_PORT=$port2
HDFS_DATANODE_HTTP_PORT=$port3
HDFS_DATANODE_HTTPS_PORT=$port4
HDFS_NN_SERVER=$HDFS_NN_SERVER
HDFS_NN_PORT=$HDFS_NN_PORT
container_name=$container_name" > $script_file
echo 'params="-p $HDFS_DATANODE_SERVER_PORT:$HDFS_DATANODE_SERVER_PORT -p $HDFS_DATANODE_IPC_PORT:$HDFS_DATANODE_IPC_PORT \
-p $HDFS_DATANODE_HTTP_PORT:$HDFS_DATANODE_HTTP_PORT -p $HDFS_DATANODE_HTTPS_PORT:$HDFS_DATANODE_HTTPS_PORT \
-e HDFS_DATANODE_SERVER_PORT=$HDFS_DATANODE_SERVER_PORT -e HDFS_DATANODE_IPC_PORT=$HDFS_DATANODE_IPC_PORT \
-e HDFS_DATANODE_HTTP_PORT=$HDFS_DATANODE_HTTP_PORT -e HDFS_DATANODE_HTTPS_PORT=$HDFS_DATANODE_HTTPS_PORT \
-e HDFSNAMENODERPC_SERVICE_HOST=$HDFS_NN_SERVER -e HDFSNAMENODERPC_SERVICE_PORT=$HDFS_NN_PORT "' >> $script_file
if [ x"" != x"$SDN_IP" ]; then
  echo 'params=$params" -e CONTAINER_IF=$CONTAINER_IF --hostname=${SDN_IP%%/*}"' >> $script_file
else
  echo 'params=$params" --hostname=$local_ip"' >> $script_file
fi
  echo '
CONTAINER_ID=`sudo docker run -d \
    $params \
    --name $container_name $IMAGE_NAME`
[ x"" != x"$SDN_IP" ] && sudo ./pipework $HOST_INTERFACE -i $CONTAINER_IF \
    $CONTAINER_ID $SDN_IP' >> $script_file
done

# Start docker container in parallel
ls ${script_prefix}*_temp.sh |xargs -P $NODE_COUNT -n 1 sh
rm -f ${script_prefix}*_temp.sh

